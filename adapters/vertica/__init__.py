import sys
import os
import vertica_python
import json
from log import Log
from .converter import convert_data


class VerticaConnection:
    def __init__(self, host, port, user, password, dbname, schema, config):
        conn_info = {
            "host": host,
            "port": port,
            "user": user,
            "password": password,
            "database": dbname,
            # autogenerated session label by default,
            # "session_label": "some_label",
            # default throw error on invalid UTF-8 results
            "unicode_error": "strict",
            # SSL is disabled by default
            "ssl": False,
            # autocommit is off by default
            "autocommit": True,
            # using server-side prepared statements is disabled by default
            "use_prepared_statements": False,
            # connection timeout is not enabled by default
            # 5 seconds timeout for a socket operation (Establishing a TCP connection or read/write operation)
            "connection_timeout": 5,
        }
        self.connection = vertica_python.connect(**conn_info)
        self.cur = self.connection.cursor()
        self.schema = schema
        self.bucket_size = 10
        self.current_bucket = []
        self.global_config = config
        with open(f"{os.path.dirname(__file__)}/config_map.json") as json_data:
            self.config_map = json.load(json_data)

    def close_connection(self):
        self.connection.close()

    def __get_mapped_data_type(self, val):
        # TODO: Not a suitable way. use has_key instead
        try:
            for dt in self.config_map["datatypes"]:
                if dt["source"] == val:
                    return dt["target"]
        except:
            return val

    def create_table(self, table_object):
        str_columns = ""
        table_name = table_object["name"]
        self.cur.execute(f"""DROP TABLE IF EXISTS {self.schema}.{table_name}""")
        Log.info(
            f"Creating table: {json.dumps(table_object, indent=4, sort_keys=True) }",
            table_name,
        )
        for col in table_object["s_columns"]:

            str_columns = f"{str_columns} {col['name']} {self.__get_mapped_data_type(col['type'])}"
            if col["length"]:
                str_columns = f"{str_columns}({col['length']})"
            if col["nullable"] == False:
                str_columns = f"{str_columns} NOT NULL"
            str_columns = f"{str_columns},"
        str_columns = f"{str_columns} dataloader_collection_ts INTEGER,"
        str_columns = f"{str_columns} dataloader_modification_ts INTEGER"
        query = f"""CREATE TABLE {self.schema}.{table_name} ({str_columns})"""
        Log.info(f"Executing query : {query}", table_name)
        self.cur.execute(query)

    def insert_values(self, table_name, values):
        query = f"""INSERT INTO {table_name} VALUES ({','.join(values)})"""
        self.current_bucket.append(query)
        if len(self.current_bucket) == self.bucket_size:
            for q in self.current_bucket:
                self.execute(q)
            self.current_bucket = []

    def insert_bulk_values(self, table, values):
        table_name = table["name"]
        for value in values:
            col_index = 0
            col_values = []

            for col in table["s_columns"]:
                val_to_convert = value[col_index]
                converted_value = convert_data(value[col_index], col["type"])
                col_values.append(converted_value)
                col_index = col_index + 1
            final_value = ""
            for val in col_values:
                if final_value is not "":
                    final_value = f"{final_value},"
                final_value = f"{final_value} {val}"

            query = f"""INSERT INTO {self.schema}.{table_name} VALUES ({final_value})"""
            Log.debug(f"Insert query: {query}", table_name)
            self.current_bucket.append(query)

    def finalize_insert(self):
        Log.info(f"Received finalization insertion")
        for q in self.current_bucket:
            self.execute(q)

    def execute(self, query):
        Log.info(f"Executing: {query}")
        self.cur.execute(query)
        query_results = self.cur.fetchall()
        return query_results
