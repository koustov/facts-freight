import sys
import os
import vertica_python
import json
from log import Log


class VerticaConnection:
    def __init__(self, host, port, user, password, dbname, schema):
        conn_info = {
            "host": host,
            "port": port,
            "user": user,
            "password": password,
            "database": dbname,
            # autogenerated session label by default,
            # "session_label": "some_label",
            # default throw error on invalid UTF-8 results
            "unicode_error": "strict",
            # SSL is disabled by default
            "ssl": False,
            # autocommit is off by default
            "autocommit": True,
            # using server-side prepared statements is disabled by default
            "use_prepared_statements": False,
            # connection timeout is not enabled by default
            # 5 seconds timeout for a socket operation (Establishing a TCP connection or read/write operation)
            "connection_timeout": 5,
        }
        self.connection = vertica_python.connect(**conn_info)
        self.cur = self.connection.cursor()
        self.schema = schema
        self.bucket_size = 10
        self.current_bucket = []
        with open(f"{os.path.dirname(__file__)}/config_map.json") as json_data:
            self.config_map = json.load(json_data)

    def close_connection(self):
        self.connection.close()

    def __get_mapped_data_type(self, val):
        # TODO: Not a suitable way. use has_key instead
        try:
            for dt in self.config_map["datatypes"]:
                if dt["source"] == val:
                    return dt["target"]
        except:
            return val

    def create_table(self, table_object):
        str_columns = ""
        self.cur.execute(
            f"""DROP TABLE IF EXISTS {self.schema}.{table_object['name']}"""
        )
        Log.info(
            f"Creating table: {json.dumps(table_object, indent=4, sort_keys=True) }"
        )
        for col in table_object["s_columns"]:

            str_columns = f"{str_columns} {col['name']} {self.__get_mapped_data_type(col['type'])}"
            if col["length"]:
                str_columns = f"{str_columns}({col['length']})"
            if col["nullable"] == False:
                str_columns = f"{str_columns} NOT NULL"
            str_columns = f"{str_columns},"
        str_columns = f"{str_columns} dataloader_collection_ts INTEGER,"
        str_columns = f"{str_columns} dataloader_modification_ts INTEGER"
        query = f"""CREATE TABLE {self.schema}.{table_object['name']} ({str_columns})"""
        Log.info(f"Executing query : {query}")
        self.cur.execute(query)

    def insert_values(self, table_name, values):
        query = f"""INSERT INTO {table_name} VALUES ({','.join(values)})"""
        self.current_bucket.append(query)
        if len(self.current_bucket) == self.bucket_size:
            for q in self.current_bucket:
                self.execute(q)
            self.current_bucket = []

    def finalize_insert(self):
        Log.info(f"Received finalization insertion")
        for q in self.current_bucket:
            self.execute(q)

    def execute(self, query):
        Log.info(f"Executing: {query}")
        self.cur.execute(query)
        query_results = self.cur.fetchall()
        return query_results
